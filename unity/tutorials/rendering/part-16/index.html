<!DOCTYPE html>
<html lang="en">
	<head prefix="og: http://ogp.me/ns#">
		<meta charset="utf-8">
		<meta property="og:url" content="https://catlikecoding.com/unity/tutorials/rendering/part-16/">
		<meta property="og:type" content="article">
		<meta property="og:image:width" content="1024">
		<meta property="og:image:height" content="512">
		<meta property="og:image" content="https://catlikecoding.com/unity/tutorials/rendering/part-16/tutorial-image.jpg">
		<meta property="og:title" content="Rendering 16">
		<meta property="og:description" content="A Unity Rendering tutorial about supporting static lightmaps and light probes. Part 16 of 20.">
		<meta property="twitter:card" content="summary_large_image">
		<meta property="twitter:creator" content="@catlikecoding">
		<meta name="viewport" content="width=768">
		<title>Rendering 16</title>
		<link href="../../tutorials.css" rel="stylesheet">

				<link rel="manifest" href="../../../../site.webmanifest">
		<link rel="mask-icon" href="../../../../safari-pinned-tab.svg" color="#aa0000">

		<script type="application/ld+json">{
			"@context": "http://schema.org",
			"@type": "WebPage",
			"mainEntity": {
				"@type": "TechArticle",
				"@id": "https://catlikecoding.com/unity/tutorials/rendering/part-16/#article",
				"headline": "Rendering 16",
				"alternativeHeadline": "Static Lighting",
				"datePublished": "2017-05-31",
				"author": { "@type": "Person", "name": "Jasper Flick", "@id": "https://catlikecoding.com/jasper-flick/#person" },
				"publisher": { "@type": "Organization", "name": "Catlike Coding", "@id": "https://catlikecoding.com/#organization" },
				"description": "A Unity Rendering tutorial about supporting static lightmaps and light probes. Part 16 of 20.",
				"image": "https://catlikecoding.com/unity/tutorials/rendering/part-16/tutorial-image.jpg",
				"dependencies": "Unity 5.6.0",
				"proficiencyLevel": "Beginner"
			},
			"breadcrumb": {
				"@type": "BreadcrumbList",
				"itemListElement": [
					{ "@type": "ListItem", "position": 1, "item": { "@id": "https://catlikecoding.com/unity/", "name": "Unity" }},
					{ "@type": "ListItem", "position": 2, "item": { "@id": "https://catlikecoding.com/unity/tutorials/", "name": "Tutorials" }},
					{ "@type": "ListItem", "position": 3, "item": { "@id": "https://catlikecoding.com/unity/tutorials/rendering/", "name": "Rendering" }}
				]
			}
		}</script>
		<script>
			var customTypes = {
				DeferredFogEffect: 1,
				MyLightingShaderGUI: 1,
				RenderingMode: 1,
				RenderingSettings: 1,
				SmoothnessSource: 1,
				TangentSpaceVisualizer: 1
			};
			
			var hasMath = false;
		</script>
	</head>
	<body>
		<header>
			<a href="../../../../index.html"><img src="../../../../catlike-coding-logo.svg" alt="Catlike Coding" width="45" height="45"></a>
			<nav>
				<ol>
					<li><a href="../../../../index.html">Catlike Coding</a></li>
					<li><a href="../../../index.html">Unity</a></li>
					<li><a href="../../../tutorials">Tutorials</a></li>
					<li><a href="../index.html">Rendering</a></li>
				</ol>
			</nav>
		</header>
		
		<main>
			<article>
				<header>
					<h1>Rendering 16</h1>
					<p>Static Lighting</p>
					<ul>
						<li>Sample from and render to lightmaps.</li>
						<li>Make baked light work with normal maps.</li>
						<li>Use a light probe group.</li>
					</ul>
				</header>

				<p>This is part 16 of a tutorial series about rendering. <a href="https://catlikecoding.com/unity/tutorials/rendering/part-15">Last time</a>, we rendered our own deferred lights. In this part, we'll move on to lightmapping.</p>
				
				<p>This tutorial was made with Unity 5.6.0.</p>
				
				<figure>
					<img src="tutorial-image.jpg" width="512" height="256">
					<figcaption>Baking some light.</figcaption>
				</figure>
				
				<section>
					<h2>Lightmapping</h2>
					
					<p>Performing lighting calculations is expensive. Deferred rendering allows us to use many lights, but shadows are still a limiting factor. If our scene is dynamic, then we cannot avoid performing these calculations. But if both the lights and the geometry are unchanging, then we could calculate the lighting once and reuse it. This allows use to put many lights in our scenes, without having to render them at run time. It also makes it possible to use area lights, which are not available as realtime lights.</p>
					
					<p>How much of the lighting is pre-computed can vary. In this tutorial, we'll go all the way and bake everything into lightmaps. So there won't be any dynamic lighting at all.</p>
						
					<p>To try out lightmapping, I've created a simple test scene that has a simple structure that provides shadow, plus a few spheres placed around and inside it. Everything has the default Unity material.</p>
					
					<figure>
						<img src="lightmapping/test-scene.png" width="350" height="190">
						<figcaption>Lightmapping test scene.</figcaption>
					</figure>
					
					<section>
						<h3>Baked Lights</h3>
						
						<p>To begin lightmapping, change the <em translate="no">Mode</em> of the only light object to <em translate="no">Baked</em> instead of <em translate="no">Realtime</em>.</p>
						
						<figure>
							<img src="lightmapping/baked-light.png" width="320" height="90">
							<figcaption>Baked main directional light.</figcaption>
						</figure>
						
						<p>After turning the main directional light into a baked light, it will no longer be included in dynamic lighting. From the point of view of dynamic objects, the light doesn't exist. The only thing that remains is the environmental lighting, which is still based on the main light.</p>
						
						<figure>
							<img src="lightmapping/no-realtime-light.png" width="350" height="190">
							<figcaption>No more direct lighting.</figcaption>
						</figure>
						
						<p>To actually enable lightmapping, turn on <em translate="no">Baked Global Illumination</em> in the <em translate="no">Mixed Lighting</em> section of the lighting window. Then set the <em translate="no">Lighting Mode</em> to <em translate="no">Baked Indirect</em>. Despite the name, this also includes direct lighting. It's just typically used to add indirect light to a scene. Also, make sure that <em translate="no">Realtime Global Illumination</em> is disabled, because we're not supporting that yet.</p>
						
						<figure>
							<img src="lightmapping/baked-indirect.png" width="320" height="153">
							<figcaption>Baked indirect mode.</figcaption>
						</figure>
					</section>
					
					<section>
						<h3>Static Geometry</h3>
						
						<p>The objects of the scene are all supposed to be fixed. They should never be moved. To communicate this to Unity, mark them as static. You can do that by enabling the <em translate="no">Static</em> toggle at the top right of the inspector window.</p>
						
						<aside>
							<h3>Do lights also have to be marked as static?</h3>
							<div>
								<p>No, that is not required. The lights only have to be set to the appropriate mode.</p>
							</div>
						</aside>
						
						<p>There are various subsystems that care about whether things are static or not. <em translate="no">Static</em> also has a dropdown menu that you can use to fine-tune which systems treat the object as being static. Right now we only care about lightmapping, but it's simplest to just make everything completely static.</p>
						
						<figure>
							<img src="lightmapping/static-object.png" width="184" height="174">
							<figcaption>Static object.</figcaption>
						</figure>
						
						<p>Whether an object is static for lightmapping purposes can also be seen and edited via the inspector of its mesh renderer.</p>
						
						<figure>
							<img src="lightmapping/lightmap-static.png" width="320" height="163">
							<figcaption>Lightmap-static object.</figcaption>
						</figure>
						
						<p>Now that all the objects are static, they will be included in the lightmapping process.</p>
						
						<figure>
							<img src="lightmapping/baked-scene.png" width="350" height="190">
							<figcaption>Scene with baked lighting.</figcaption>
						</figure>
						
						<p>Note that the lightmapped result is less bright than when using realtime lighting. That's because the specular lighting is missing, it's only diffuse lighting. Specular lighting depends on the view angle, so it depends on the camera. Typically, the camera is mobile, so it cannot be included in lightmapping. This limitation means that lightmapping can work for subtle lights and dull surfaces, but not for strong direct lights or shiny surfaces. If you want specular lighting, you'll have to use realtime lights. So you often end up with a mix of baked and realtime lights.</p>
						
						<aside>
							<h3>Why don't I get baked light?</h3>
							<div>
								<p>To make sure that the lightmaps are actually generated and updated when required, enable <em translate="no">Auto Generate</em> at the bottom of the lighting window. Otherwise, you have to manually generate new lightmaps.</p>
								
								<figure>
									<img src="lightmapping/auto-generate.png" width="320" height="24">
									<figcaption>Automatically generate lightmaps.</figcaption>
								</figure>
							</div>
						</aside>
					</section>
					
					
					<section>
						<h3>Lightmapping Settings</h3>
						
						<p>The lighting window contains a section dedicated to lightmapping settings. Here you can make a trade-off between quality, size, and baking time. You can also switch between the <em translate="no">Enlighten</em> lightmapping engine and the <em translate="no">Progressive</em> lightmapper. The latter incrementally generates lightmaps, giving priority to what's visible in the scene view, which is convenient while editing. I used <em translate="no">Enlighten</em> for this tutorial.</p>
						
						<figure>
							<img src="lightmapping/lightmap-settings.png" width="320" height="288">
							<figcaption>Default lightmap settings.</figcaption>
						</figure>
						
						<p>Before you do anything else, set the <em translate="no">Directional Mode</em> to <em translate="no">Non-Direction</em>. We'll deal with the other mode later.</p>
						
						<figure>
							<img src="lightmapping/non-directional.png" width="320" height="20">
							<figcaption>Non-directional lightmaps.</figcaption>
						</figure>
						
						<p>The baked lighting is stored in textures. You can view them by switching the lighting window from <em translate="no">Scene</em> to <em translate="no">Global Maps</em> mode. With the default settings, my test scene easily fits in a single 1024&times;1024 map.</p>
						
						<figure>
							<img src="lightmapping/lightmap.png" width="310" height="204">
							<figcaption>The lightmap.</figcaption>
						</figure>
						
						<p>Unity's default objects all have UV coordinates configured for lightmapping. For imported meshes, you either provide your own coordinates, or let Unity generate them for you. After baking, the texture unwraps can been seen in the lightmap. How much space they require depends on the object's size in the scene and the lightmap resolution settings. If they don't fit in a single map, Unity will create additional maps.</p>
						
						<figure>
							<img alt="low" src="lightmapping/low-quality.png" width="370" height="220">
							<img alt="higher" src="lightmapping/higher-quality.png" width="370" height="220">
							<figcaption>Lightmap resolution makes a big difference.</figcaption>
						</figure>
						
						<p>Which settings are best varies per project. You have to tweak the settings until you arrive at a good trade-off. Note that the visual quality also greatly depends on the quality of the texture unwrap used for lightmapping. The presence of absence of texture seams can produce obvious artifacts. Unity's default sphere is a good example of this. It is not suited for lightmapping.</p>
					</section>
					
					<section>
						<h3>Indirect Light</h3>
						
						<p>While baking light means that we lose specular lighting, we gain indirect lighting. This is light that bounces off multiple surfaces before it reaches our eyes. Because light bounces around corners, areas that would otherwise be shadowed still get illuminated. We cannot compute this at realtime, but we can include bounced light while baking.</p>
						
						<p>To clearly see the difference between realtime and baked lighting, set the intensity of the environmental lighting to zero. This eliminates the skybox, so all light comes from the directional light only.</p>
						
						<figure>
							<img alt="realtime" src="lightmapping/no-environmental-realtime.png" width="350" height="190">
							<img alt="lightmapped" src="lightmapping/no-environmental-lightmapped.png" width="350" height="190">
							<figcaption>No environmental lighting, realtime vs. lightmapped.</figcaption>
						</figure>
						
						<p>Each time that a photon bounces, it loses some of its energy, getting colored by the material it interacted with. Unity takes this into consideration when baking indirect light. As a result, objects get colored based on what's nearby.</p>
						
						<figure>
							<img alt="realtime" src="lightmapping/green-floor-realtime.png" width="350" height="190">
							<img alt="lightmapped" src="lightmapping/green-floor-lightmapped.png" width="350" height="190">
							<figcaption>Green floor, realtime vs. lightmapped.</figcaption>
						</figure>
						
						<p>Emissive surfaces also affect baked light. They become indirect light sources.</p>
						
						<figure>
							<img alt="realtime" src="lightmapping/emissive-realtime.png" width="350" height="190">
							<img alt="lightmapped" src="lightmapping/emissive-lightmapped.png" width="350" height="190">
							<figcaption>Emissive floor, realtime vs. lightmapped.</figcaption>
						</figure>
						
						<p>A special setting for indirect light is <em translate="no">Ambient Occlusion</em>. This refers to the shadowing of indirect light that happens in corners and creases. It is an artificial boost, which can enhance the feeling of depth.</p>
						
						<figure>
							<img alt="settings" src="lightmapping/ambient-occlusion-settings.png" width="320" height="74">
							<img alt="scene" src="lightmapping/ambient-occlusion.png" width="350" height="190">
							<figcaption>Using ambient occlusion.</figcaption>
						</figure>
						
						<p>The ambient occlusion effect is solely based on how hidden a surface is. It doesn't consider where the light is actually coming from. This doesn't always make sense, for example in combination with emissive surfaces.</p>
						
						<figure>
							<img src="lightmapping/ambient-occlusion-incorrect.png" width="350" height="190">
							<figcaption>Obviously wrong ambient occlusion.</figcaption>
						</figure>
					</section>
					
					<section>
						<h3>Transparency</h3>
						
						<p>Lightmapping can deal with semitransparent surfaces, up to a point. Light will pass through them, although its color doesn't get filtered by them.</p>
						
						<figure>
							<img src="lightmapping/semitransparent-roof.png" width="330" height="220">
							<figcaption>Semitransparent roof.</figcaption>
						</figure>
						
						<p>Cutout materials work too.</p>
						
						<figure>
							<img src="lightmapping/cutout-roof.png" width="330" height="220">
							<figcaption>Cutout roof.</figcaption>
						</figure>
						
						<p>However, this only works when using closed surfaces. When using single-sided geometry like quads, the light becomes corrupted on the non-existing side. This is fine when there's nothing on the other side, but leads to problems when working with single-sided transparent surfaces.</p>
						
						<figure>
							<img src="lightmapping/quad-errors.png" width="190" height="190">
							<figcaption>Quad produces errors.</figcaption>
						</figure>
						
						<p>To deal with this, you have to tell the lightmapping system to treat these surfaces as transparent. This can be done via custom lightmapping settings. You can create these via <em translate="no">Asset / Create / Lightmap Parameters</em>. These assets allow you to customize the lightmap calculations per object. In this case, we're only interested in indicating that we're dealing with a transparent object. So enable <em translate="no">Is Transparent</em>. Although it is part of the <em translate="no">Precomputed Realtime GI</em> section, it will affect all baked lighting.</p>
						
						<figure>
							<img src="lightmapping/lightmap-parameters.png" width="320" height="168">
							<figcaption>Indicating transparency.</figcaption>
						</figure>
						
						<p>To use these settings, select them via the object's mesh renderer inspector. Your asset's name will show up in the dropdown list for <em translate="no">Lightmap Parameters</em>.</p>
						
						<figure>
							<img alt="inspector" src="lightmapping/using-custom-parameters.png" width="320" height="234">
							<img alt="scene" src="lightmapping/quad-correct.png" width="190" height="190">
							<figcaption>Using custom parameters for transparent quads.</figcaption>
						</figure>
						
						<p>Marking an object as transparent also changes how it contributes to indirect lighting. Transparent objects let indirect light pass, while opaque objects block it.</p>
					</section>
					
					<a href="lightmapping/lightmapping.unitypackage" download rel="nofollow">unitypackage</a>
				</section>
				
				<section>
					<h2>Using Lightmaps</h2>
					
					<p>Now that we know how lightmaps work, we can add support for them to <em translate="no">My First Lighting Shader</em>. The first step of this process is to sample the lightmaps. Adjust the spheres in the scene so they use the white material with our shader.</p>
					
					<figure>
						<img src="using-lightmaps/spheres-custom.png" width="350" height="190">
						<figcaption>Spheres using our white material.</figcaption>
					</figure>
					
					<section>
						<h3>Lightmapped Shader Variants</h3>
						
						<p>When a shader is supposed to use lightmaps, Unity will look for a variant associated with the <em translate="no">LIGHTMAP_ON</em> keyword. So we have to add a multi-compile directive for this keyword. When using the forward rendering path, lightmaps are sampled in the base pass only.</p>
						
						<pre translate="no" class="shader">			#pragma multi_compile _ SHADOWS_SCREEN
			#pragma multi_compile _ VERTEXLIGHT_ON
			<ins>#pragma multi_compile _ LIGHTMAP_ON</ins>
			#pragma multi_compile_fog</pre>
						
						<p>When lightmaps are used, Unity will never include vertex lights. Their keywords are mutually exclusive. So we don't need a variant with both <em translate="no">VERTEXLIGHT_ON</em> and <em translate="no">LIGHTMAP_ON</em> at the same time.</p>
						
						<pre translate="no" class="shader">			#pragma multi_compile _ SHADOWS_SCREEN
<del>//			#pragma multi_compile _ VERTEXLIGHT_ON</del>
<del>//			#pragma multi_compile _ LIGHTMAP_ON</del>
			<ins>#pragma multi_compile _ LIGHTMAP_ON VERTEXLIGHT_ON</ins>
			#pragma multi_compile_fog</pre>
						
						<p>Lightmaps are also supported in the deferred rendering path, so add the keyword to the deferred pass as well.</p>
						
						<pre translate="no" class="shader">			#pragma multi_compile _ UNITY_HDR_ON
			<ins>#pragma multi_compile _ LIGHTMAP_ON</ins></pre>
					</section>
					
					<section>
						<h3>Lightmap Coordinates</h3>
						
						<p>The coordinates used to sample the lightmap are stored in the second texture coordinates channel, uv1. So add this channel to <code class="shader">VertexData</code> in <em translate="no">My Lighting</em>.</p>
						
						<pre translate="no" class="shader">struct VertexData {
	float4 vertex : POSITION;
	float3 normal : NORMAL;
	float4 tangent : TANGENT;
	float2 uv : TEXCOORD0;
	<ins>float2 uv1 : TEXCOORD1;</ins>
};</pre>
						
						<p>The lightmap coordinates have to be interpolated as well. Because they're mutually exclusive with vertex lights, both can use <code class="shader">TEXCOORD6</code>.</p>
						
						<pre translate="no" class="shader">struct Interpolators {
	&hellip;

	#if defined(VERTEXLIGHT_ON)
		float3 vertexLightColor : TEXCOORD6;
	#endif

	<ins>#if defined(LIGHTMAP_ON)</ins>
		<ins>float2 lightmapUV : TEXCOORD6;</ins>
	<ins>#endif</ins>
};</pre>
						
						<p>The coordinates from the vertex data define the texture unwrap of the mesh for lightmapping. But this doesn't tell us where in the lightmap this unwrap is placed, nor its size. We have to scale and offset the coordinates to arrive at the final lightmap coordinates. This work like the transformation applied to regular texture coordinates, except that the transformation is object-specific, instead of material-specific. The lightmap texture is define in <em translate="no">UnityShaderVariables</em> as <code class="shader">unity_Lightmap</code>.</p>
						
						<pre translate="no" class="shader">Interpolators MyVertexProgram (VertexData v) {
	&hellip;

	i.uv.xy = TRANSFORM_TEX(v.uv, _MainTex);
	i.uv.zw = TRANSFORM_TEX(v.uv, _DetailTex);

	<ins>#if defined(LIGHTMAP_ON)</ins>
		<ins>i.lightmapUV = TRANSFORM_TEX(v.uv1, unity_Lightmap);</ins>
	<ins>#endif</ins>

	&hellip;
}</pre>
						
						<p>Unfortunately, we cannot use the convenient <code class="shader">TRANSFORM_TEX</code> macro, because it assumes that the lightmap transformation is defined as <code class="shader">unity_Lightmap_ST</code>, while it actually is <code class="shader">unity_LightmapST</code>. Due to this inconsistency, we have to do it manually.</p>
						
						<pre translate="no" class="shader">		i.lightmapUV = <ins>v.uv1 * unity_LightmapST.xy + unity_LightmapST.zw</ins>;</pre>
					</section>
					
					<section>
						<h3>Sampling the Lightmap</h3>
						
						<p>Because the lightmap data is considered to be indirect light, we'll sample it in the <code class="shader">CreateIndirectLight</code> function. When lightmaps are available, we have to use them as the source for the indirect light, instead of the spherical harmonics.</p>
						
						<pre translate="no" class="shader">UnityIndirect CreateIndirectLight (Interpolators i, float3 viewDir) {
	&hellip;
	
	#if defined(VERTEXLIGHT_ON)
		indirectLight.diffuse = i.vertexLightColor;
	#endif

	#if defined(FORWARD_BASE_PASS) || defined(DEFERRED_PASS)
		<ins>#if defined(LIGHTMAP_ON)</ins>
			<ins>indirectLight.diffuse = 0;</ins>
		<ins>#else</ins>
			indirectLight.diffuse += max(0, ShadeSH9(float4(i.normal, 1)));
		<ins>#endif</ins>
		float3 reflectionDir = reflect(-viewDir, i.normal);
		&hellip;
	#endif

	return indirectLight;
}</pre>
						
						<aside>
							<h3>Why assign instead of add to <code class="shader">indirectLight.diffuse</code>?</h3>
							<div>
								<p>It's a hint that lightmaps are never combined with vertex lights.</p>
							</div>
						</aside>
						
						<p>The exact form of <code class="shader">unity_Lightmap</code> depends on the target platform. It is defined as <code class="shader">UNITY_DECLARE_TEX2D(unity_Lightmap)</code>. To sample it, we'll use the <code class="shader">UNITY_SAMPLE_TEX2D</code> macro instead of <code class="shader">tex2D</code>. We'll get to the reason for this later.</p>
						
						<pre translate="no" class="shader">			indirectLight.diffuse =
				<ins>UNITY_SAMPLE_TEX2D(unity_Lightmap, i.lightmapUV)</ins>;</pre>
						
						<figure>
							<img src="using-lightmaps/raw-lightmap.png" width="350" height="190">
							<figcaption>Using raw lightmap data.</figcaption>
						</figure>
						
						<p>We now get baked indirect lighting, but it looks wrong. That's because the lightmap data has been encoded. The colors are either stored in RGBM format or at half intensity, to support high-intensity light. The <code class="shader">DecodeLightmap</code> function from <em translate="no">UnityCG</em> takes care of decoding this for us.</p>
						
						<pre translate="no" class="shader">			indirectLight.diffuse = <ins>DecodeLightmap(</ins>
				UNITY_SAMPLE_TEX2D(unity_Lightmap, i.lightmapUV)
			<ins>)</ins>;</pre>
						
						<figure>
							<img src="using-lightmaps/decoded-lightmap.png" width="350" height="190">
							<figcaption>Using decoded lightmap data.</figcaption>
						</figure>
					</section>
					
					<a href="using-lightmaps/using-lightmaps.unitypackage" download rel="nofollow">unitypackage</a>
				</section>
				
				<section>
					<h2>Creating Lightmaps</h2>
					
					<p>While lightmaps already seem to work with our shader, that's only true for our simple test scene. Currently, the lightmapper always treats our objects as opaque and solid white, even when they're not. We have to make some adjustments to our shader and even add another pass to fully support lightmapping.</p>
					
					<p>From now on, use our own shader for all objects in the scene. The default material should no longer be used.</p>
					
					<section>
						<h3>Semitransprant Shadows</h3>
						
						<p>The lightmapper doesn't use the realtime rendering pipeline, so it doesn't use our shader to do its work. This is most obvious when trying to use semitransparent shadows. Make the roof cube semitransparent by giving it a material with its tint's alpha component set to less that 1.</p>
						
						<figure>
							<img src="creating-lightmaps/semitransparent-roof-incorrect.png" width="330" height="220">
							<figcaption>Semitransparent roof, incorrect.</figcaption>
						</figure>
						
						<p>The lightmapper still treats the roof as if it were solid, which is incorrect. It uses the render type of the material to determine how to treat surfaces, which should have told it that our object is semitransparent. In fact, it does know that the roof is semitransparent, it just treats it as if we made it full opaque. This happens because it uses the alpha component of the <em translate="no">_Color</em> material property, along with the main texture, to set the opacity. But we don't have that property, we use <em translate="no">_Tint</em> instead!</p>
						
						<p>Unfortunately, there is not way to tell the lightmapper which property to use. So to make lightmapping work, we have no other option than to replace our usage of <em translate="no">_Tint</em> with <em translate="no">_Color</em>. First, update the properties of our shader.</p>
						
						<pre translate="no" class="shader">	Properties {
<del>//		_Tint ("Tint", Color) = (1, 1, 1, 1)</del>
		<ins>_Color ("Tint", Color) = (1, 1, 1, 1)</ins>
		&hellip;
	}</pre>
						
						<p>Then, to keep our shader functional, we also have to replace the corresponding variable in <em translate="no">My Lighting</em>.</p>
						
						<pre translate="no" class="shader"><del>//float4 _Tint;</del>
<ins>float4 _Color;</ins>
&hellip;

float3 GetAlbedo (Interpolators i) {
	float3 albedo = tex2D(_MainTex, i.uv.xy).rgb * <ins>_Color</ins>.rgb;
	&hellip;
}

float GetAlpha (Interpolators i) {
	float alpha = <ins>_Color</ins>.a;
	&hellip;
}</pre>
						
						<p>The same goes for <em translate="no">My Shadows</em>.</p>
						
						<pre translate="no" class="shader"><del>//float4 _Tint;</del>
<ins>float4 _Color;</ins>
&hellip;

float GetAlpha (Interpolators i) {
	float alpha = <ins>_Color</ins>.a;
	&hellip;
}</pre>
						
						<p>And we also have to adjust <code>MyLightingShaderGUI</code>.</p>
						
						<pre translate="no">	void DoMain () {
		GUILayout.Label("Main Maps", EditorStyles.boldLabel);

		MaterialProperty mainTex = FindProperty("_MainTex");
		editor.TexturePropertySingleLine(
			MakeLabel(mainTex, "Albedo (RGB)"), mainTex, FindProperty(<ins>"_Color"</ins>)
		);

		&hellip;
	}
</pre>
						
						<figure>
							<img src="creating-lightmaps/semitransparent-roof-correct.png" width="330" height="220">
							<figcaption>Semitransparent roof, correct.</figcaption>
						</figure>
					</section>
					
					<section>
						<h3>Cutout Shadows</h3>
						
						<p>Cutout shadows have a similar problem. The lightmapper expects the alpha cutoff value to be stored in the <em translate="no">_Cutoff</em> property, but we're using <em translate="no">_AlphaCutoff</em>. As a result, it uses a default cutoff of 1.</p>
						
						<figure>
							<img src="creating-lightmaps/cutout-roof-incorrect.png" width="330" height="220">
							<figcaption>Cutout roof, incorrect.</figcaption>
						</figure>
						
						<p>The solution is to again adopt Unity's naming convention. So replace the property.</p>
						
						<pre translate="no" class="shader">	Properties {
		&hellip;

<del>//		_AlphaCutoff ("Alpha Cutoff", Range(0, 1)) = 0.5</del>
		<ins>_Cutoff ("Alpha Cutoff", Range(0, 1)) = 0.5</ins>

		&hellip;
	}</pre>
						
						<p>Adjust <em translate="no">My Lighting</em> to match the new name.</p>
						
						<pre translate="no" class="shader"><del>//float _AlphaCutoff;</del>
<ins>float _Cutoff;</ins>

&hellip;

FragmentOutput MyFragmentProgram (Interpolators i) {
	float alpha = GetAlpha(i);
	#if defined(_RENDERING_CUTOUT)
		clip(alpha - <ins>_Cutoff</ins>);
	#endif

	&hellip;
}</pre>
						
						<p>Update <em translate="no">My Shadows</em> too.</p>
						
						<pre translate="no" class="shader"><del>//float _AlphaCutoff;</del>
<ins>float _Cutoff;</ins>

&hellip;

float4 MyShadowFragmentProgram (Interpolators i) : SV_TARGET {
	float alpha = GetAlpha(i);
	#if defined(_RENDERING_CUTOUT)
		clip(alpha - <ins>_Cutoff</ins>);
	#endif

	&hellip;
}</pre>
						
						<p>And <code>MyLightingShaderGUI</code> as well.</p>
						
						<pre translate="no">	void DoAlphaCutoff () {
		MaterialProperty slider = FindProperty(<ins>"_Cutoff"</ins>);
		EditorGUI.indentLevel += 2;
		editor.ShaderProperty(slider, MakeLabel(slider));
		EditorGUI.indentLevel -= 2;
	}
</pre>
						
						<figure>
							<img src="creating-lightmaps/cutout-roof-correct.png" width="330" height="220">
							<figcaption>Cutout roof, correct.</figcaption>
						</figure>
					</section>
					
					<section>
						<h3>Adding a Meta Pass</h3>
						
						<p>The next step is to make sure that the lightmapper uses the correct surface albedo and emission. Right now, everything is always solid white. You can see this by making the floor green. It should result in green indirect light, but it stays white.</p>
						
						<figure>
							<img src="creating-lightmaps/green-floor-incorrect.png" width="350" height="190">
							<figcaption>Green floor, incorrect.</figcaption>
						</figure>
						
						<p>To figure out the surface color of objects, the lightmapper looks for a shader pass with its light mode set to <em translate="no">Meta</em>. This pass is only used by the lightmapper and isn't included in builds. So let's add such a pass to our shader. It's a basic pass that shouldn't use culling. Put the code for it in a new <em translate="no">My Lightmapping</em> include file.</p>
						
						<pre translate="no" class="shader">		<ins>Pass {</ins>
			<ins>Tags {</ins>
				<ins>"LightMode" = "Meta"</ins>
			<ins>}</ins>

			<ins>Cull Off</ins>

			<ins>CGPROGRAM</ins>

			<ins>#pragma vertex MyLightmappingVertexProgram</ins>
			<ins>#pragma fragment MyLightmappingFragmentProgram</ins>

			<ins>#include "My Lightmapping.cginc"</ins>

			<ins>ENDCG</ins>
		<ins>}</ins></pre>
						
						<p>Now we need to determine the albedo, specular color, smoothness, and emission. So copy the required variables and functions from <em translate="no">My Lighting</em> to <em translate="no">My Lightmapping</em>. We only need the vertex position and uv coordinates for this. Normals and tangents are not used, but we will need the lightmap coordinates in the vertex shader. 
						
						
						
						<pre translate="no" class="shader">#if !defined(MY_LIGHTMAPPING_INCLUDED)
#define MY_LIGHTMAPPING_INCLUDED

#include "UnityPBSLighting.cginc"

float4 _Color;
sampler2D _MainTex, _DetailTex, _DetailMask;
float4 _MainTex_ST, _DetailTex_ST;

sampler2D _MetallicMap;
float _Metallic;
float _Smoothness;

sampler2D _EmissionMap;
float3 _Emission;

struct VertexData {
	float4 vertex : POSITION;
	float2 uv : TEXCOORD0;
	float2 uv1 : TEXCOORD1;
};

struct Interpolators {
	float4 pos : SV_POSITION;
	float4 uv : TEXCOORD0;
};

float GetDetailMask (Interpolators i) {
	&hellip;
}

float3 GetAlbedo (Interpolators i) {
	&hellip;
}

float GetMetallic (Interpolators i) {
	&hellip;
}

float GetSmoothness (Interpolators i) {
	&hellip;
}

float3 GetEmission (Interpolators i) {
	&hellip;
}

#endif</pre>
						
						<p>We can use the functions as they are, except for <code class="shader">GetEmission</code>. That function only does something when it's used in either the forwards base pass or the deferred pass. In <em translate="no">My Lightmapping</em>, we can simply remove this restriction.</p>
						
						<pre translate="no" class="shader">float3 GetEmission (Interpolators i) {
<del>//	#if defined(FORWARD_BASE_PASS) || defined(DEFERRED_PASS)</del>
	#if defined(_EMISSION_MAP)
		return tex2D(_EmissionMap, i.uv.xy) * _Emission;
	#else
		return _Emission;
	#endif
<del>//	#else</del>
<del>//		return 0;</del>
<del>//	#endif</del>
}</pre>
						
						<p>These functions will only work when the appropriate keywords are defined, so add shader features for them to the pass.</p>
						
						<pre translate="no">			#pragma vertex MyLightmappingVertexProgram
			#pragma fragment MyLightmappingFragmentProgram

			<ins>#pragma shader_feature _METALLIC_MAP</ins>
			<ins>#pragma shader_feature _ _SMOOTHNESS_ALBEDO _SMOOTHNESS_METALLIC</ins>
			<ins>#pragma shader_feature _EMISSION_MAP</ins>
			<ins>#pragma shader_feature _DETAIL_MASK</ins>
			<ins>#pragma shader_feature _DETAIL_ALBEDO_MAP</ins>

			#include "My Lightmapping.cginc"</pre>
					</section>
					
					<section>
						<h3>Vertex Program</h3>
						
						<p>The vertex program is simple for this pass. Convert the position and transform the texture coordinates.</p>
						
						<pre translate="no" class="shader"><ins>Interpolators MyLightmappingVertexProgram (VertexData v) {</ins>
	<ins>Interpolators i;</ins>
    <ins>i.pos = UnityObjectToClipPos(v.vertex);</ins>

	<ins>i.uv.xy = TRANSFORM_TEX(v.uv, _MainTex);</ins>
	<ins>i.uv.zw = TRANSFORM_TEX(v.uv, _DetailTex);</ins>
	<ins>return i;</ins>
<ins>}</ins></pre>
						
						<p>However, we're not actually rendering for a camera, we're rendering for the lightmapper. We're associating colors with an object's texture unwrap in the lightmap. To perform this mapping, we have to use the lightmap coordinates instead of the vertex position, with the appropriate transformation.</p>
						
						<pre translate="no" class="shader">	Interpolators i;
	<ins>v.vertex.xy = v.uv1 * unity_LightmapST.xy + unity_LightmapST.zw;</ins>
	<ins>v.vertex.z = 0;</ins>
    i.pos = UnityObjectToClipPos(v.vertex);</pre>
						
						<p>It turns out that to make this work on all machines, the Z coordinate of the vertex position has to be used somehow, even though we don't use it. Unity's shaders use a dummy value for this, so we'll simply do the same.</p>
						
						<pre translate="no" class="shader">	Interpolators i;
	v.vertex.xy = v.uv1 * unity_LightmapST.xy + unity_LightmapST.zw;
	v.vertex.z = <ins>v.vertex.z > 0 ? 0.0001 : 0</ins>;
    i.pos = UnityObjectToClipPos(v.vertex);</pre>
					</section>
					
					<section>
						<h3>Fragment Program</h3>
						
						<p>In the fragment program, we'll have to output both the albedo and emissive colors. The lightmapper will do this by performing the pass twice, once for each output. To make this easy for us, we can use the <code class="shader">UnityMetaFragment</code> function defined in the <em translate="no">UnityMetaPass</em> include file. It has a <code class="shader">UnityMetaInput</code> structure as parameter which contains both the albedo and emission. The function will decide which one to output and how to encode it.</p>
						
						<p><code class="shader">UnityMetaInput</code> also contains the specular color, even though it isn't stored in the lightmap. It's used for some editor visualizations, which we'll ignore at this point.</p>
						
						<pre translate="no" class="shader">#include "UnityPBSLighting.cginc"
<ins>#include "UnityMetaPass.cginc"</ins>

&hellip;

<ins>float4 MyLightmappingFragmentProgram (Interpolators i) : SV_TARGET {</ins>
	<ins>UnityMetaInput surfaceData;</ins>
	<ins>surfaceData.Emission = 0;</ins>
	<ins>surfaceData.Albedo = 0;</ins>
	<ins>surfaceData.SpecularColor = 0;</ins>
	<ins>return UnityMetaFragment(surfaceData);</ins>
<ins>}</ins></pre>
						
						<aside>
							<h3>What does <code class="shader">UnityMetaFragment</code> look like?</h3>
							<div>
								
								<p>The <code class="shader">unity_MetaFragmentControl</code> variable contains flags which tell the function whether to output the albedo or emissive color. There's also code for an editor visualization variant, but I cut that out because it's not relevant here.</p>
								
								<pre translate="no" class="shader">half4 UnityMetaFragment (UnityMetaInput IN) {
	half4 res = 0;
	if (unity_MetaFragmentControl.x) {
		res = half4(IN.Albedo,1);

		// d3d9 shader compiler doesn't like NaNs and infinity.
		unity_OneOverOutputBoost = saturate(unity_OneOverOutputBoost);

		// Apply Albedo Boost from LightmapSettings.
		res.rgb = clamp(
			pow(res.rgb, unity_OneOverOutputBoost), 0, unity_MaxOutputValue
		);
	}
	if (unity_MetaFragmentControl.y) {
		half3 emission;
		if (unity_UseLinearSpace)
			emission = IN.Emission;
		else
			emission = GammaToLinearSpace (IN.Emission);

		res = UnityEncodeRGBM(emission, EMISSIVE_RGBM_SCALE);
	}
	return res;
}</pre>
							</div>
						</aside>
						
						<figure>
							<img src="creating-lightmaps/no-indirect.png" width="350" height="190">
							<figcaption>Indirect light set to zero.</figcaption>
						</figure>
						
						<p>To get the emissive color, we can simple use <code class="shader">GetEmission</code>. To get the albedo, we have to use <code class="shader">DiffuseAndSpecularFromMetallic</code> again. That function has output parameters for the specular color and reflectivity, so we have to provide those even though we don't use them outside the function. We can use <code class="shader">surfaceData.SpecularColor</code> to catch the specular color.</p>
						
						<pre translate="no" class="shader">float4 MyLightmappingFragmentProgram (Interpolators i) : SV_TARGET {
	UnityMetaInput surfaceData;
	surfaceData.Emission = <ins>GetEmission(i)</ins>;
	<ins>float oneMinusReflectivity;</ins>
	surfaceData.Albedo = <ins>DiffuseAndSpecularFromMetallic(</ins>
		<ins>GetAlbedo(i), GetMetallic(i),</ins>
		<ins>surfaceData.SpecularColor, oneMinusReflectivity</ins>
	<ins>);</ins>
<del>//	surfaceData.SpecularColor = 0;</del>
	return UnityMetaFragment(surfaceData);
}</pre>
						
						<figure>
							<img src="creating-lightmaps/indirect-light.png" width="350" height="190">
							<figcaption>Colored indirect light.</figcaption>
						</figure>
						
						<p>This works for indirect light, but emissive light might not yet appear in the light map. That's because the lightmapper doesn't always include a pass for the emissive light. Materials have to signal that they have emissive light to contribute to the baking process. This is done via the <code>Material.globalIlluminationFlags</code> property. For now, let's always indicate that the emissive light should be baked, when its emission is edited.</p>
						
						<pre translate="no">	void DoEmission () {
		&hellip;
		if (EditorGUI.EndChangeCheck()<ins>) {</ins>
			<ins>if (</ins>tex != map.textureValue) {
				SetKeyword("_EMISSION_MAP", map.textureValue);
			<ins>}</ins>

			<ins>foreach (Material m in editor.targets) {</ins>
				<ins>m.globalIlluminationFlags =</ins>
					<ins>MaterialGlobalIlluminationFlags.BakedEmissive;</ins>
			<ins>}</ins>
		}
	}</pre>
					</section>
					
					<section>
						<h3>Rough Metals</h3>
						
						<p>Our shader now appears to work correctly, but it doesn't exactly match the results of the standard shader. This is most obvious when using a colored metal with very low smoothness.</p>
						
						<figure>
							<img alt="standard" src="creating-lightmaps/metal-standard.png" width="350" height="190">
							<img alt="custom" src="creating-lightmaps/metal-custom.png" width="350" height="190">
							<figcaption>Rough green metal, standard vs. our shader.</figcaption>
						</figure>
						
						<p>The idea is that very rough metals should produce more indirect light than our current calculations suggest. The standard shader compensates for this by adding part of the specular color to the albedo. It uses the <code class="shader">SmoothnessToRoughness</code> function from <em translate="no">UnityStandardBRDF</em> to determine a roughness value based on smoothness, halves it, and uses that to scale the specular color.</p>
						
						<pre translate="no" class="shader">	<ins>float roughness = SmoothnessToRoughness(GetSmoothness(i)) * 0.5;</ins>
	<ins>surfaceData.Albedo += surfaceData.SpecularColor * roughness;</ins>

	return UnityMetaFragment(surfaceData);</pre>
						
						<aside>
							<h3>What does <code class="shader">SmoothnessToRoughness</code> compute?</h3>
							<div>
								<p>The conversion is one minus the smoothness value, squared. This squared mapping from smoothness to roughness ends up producing better results than just a linear conversion.</p>
								
								<pre translate="no" class="shader">// Smoothness is the user facing name
// it should be perceptualSmoothness
// but we don't want the user to have to deal with this name
half SmoothnessToRoughness(half smoothness) {
	return (1 - smoothness) * (1 - smoothness);
}</pre>
							</div>
						</aside>
						
						<figure>
							<img src="creating-lightmaps/adjusted-albedo.png" width="350" height="190">
							<figcaption>Tweaked albedo.</figcaption>
						</figure>
					</section>
					
					<a href="creating-lightmaps/creating-lightmaps.unitypackage" download rel="nofollow">unitypackage</a>
				</section>
				
				<section>
					<h2>Directional Lightmaps</h2>
					
					<p>The lightmapper only uses the vertex data of geometry, it doesn't take normal maps into account. The lightmap resolution is too low to capture the details provided by typical normal maps. This means that the static lighting will be flat. This becomes very obvious when using a material with a normal map.</p>
					
					<figure>
						<img alt="realtime" src="directional-lightmaps/normal-maps-realtime.png" width="350" height="190">
						<img alt="lightmapped" src="directional-lightmaps/normal-maps-lightmapped.png" width="350" height="190">
						<figcaption>Using normal maps, realtime vs. lightmapped.</figcaption>
					</figure>
					
					<p>When switching from realtime to baked lighting, the influence of the normal maps almost completely disappear. You only see them because they're still used for environmental reflections.</p>
					
					<section>
						<h3>Directionality</h3>
						
						<p>It is possible to make normal maps work with baked lighting, by changing the <em translate="no">Directional Mode</em> back to <em translate="no">Directional</em>.</p>
						
						<figure>
							<img src="directional-lightmaps/directional-mode.png" width="342" height="22">
							<figcaption>Enabling directional lightmaps again.</figcaption>
						</figure>
						
						<p>When using directional lightmaps, Unity will create two maps instead of just one. The first map contains the lighting information as usual, known as the intensity map. The second map is known as the directionality map. It contains the direction that most of the baked light is coming from.</p>
						
						<figure>
							<img src="directional-lightmaps/intensity-directionality.png" width="360" height="200">
							<figcaption>Intensity and directionality maps.</figcaption>
						</figure>
						
						<p>When the directionality map is available, we can use it to perform simple diffuse shading with the baked light. This makes it possible to apply normal maps. Note that only a single light direction is known, so the shading will be an approximation. As long as there is at least a fairly dominant light direction when the lighting is strong, the results will appear fine.</p>
					</section>
					
					<section>
						<h3>Sampling the Direction</h3>
						
						<p>When directional lightmaps are available, Unity will look for a shader variant with both the <em translate="no">LIGHTMAP_ON</em> and <em translate="no">DIRLIGHTMAP_COMBINED</em> keywords. Instead of adding multi-compile directives for that manually, we can use <code class="shader">#pragma multi_compile_fwdbase</code> in the forward base pass. It will take care of all the lightmapping keywords, and also the <em translate="no">VERTEXLIGHT_ON</em> keyword.</p>
						
						<pre translate="no" class="shader"><del>//			#pragma multi_compile _ SHADOWS_SCREEN</del>
<del>//			#pragma multi_compile _ LIGHTMAP_ON VERTEXLIGHT_ON</del>
			<ins>#pragma multi_compile_fwdbase</ins>
			#pragma multi_compile_fog</pre>
						
						<p>We can do the same for the deferred pass, but here we have to use the <code class="shader">#pragma multi_compile_prepassfinal</code> directive. It takes care of the lightmapping and the HDR keywords.</p>
						
						<aside>
							<h3>What is prepass final?</h3>
							<div>
								<p>Unity 4 used a different deferred rendering pipeline than later versions. In Unity 5 it is known as legacy deferred lighting. This approach had more passes. Prepass final is terminology from that time. Instead of introducing a new directive, <code class="shader">#pragma multi_compile_prepassfinal</code> is also used for the current deferred pass.</p>
							</div>
						</aside>
						
						<pre translate="no" class="shader"><del>//			#pragma multi_compile _ UNITY_HDR_ON</del>
<del>//			#pragma multi_compile _ LIGHTMAP_ON</del>
			<ins>#pragma multi_compile_prepassfinal</ins></pre>
						
						<p>The baked light direction is needed directly after retrieving the baked light itself, in <code class="shader">CreateIndirectLight</code>. The directionality map is made available via <code class="shader">unity_LightmapInd</code>.</p>
						
						<pre translate="no" class="shader">		#if defined(LIGHTMAP_ON)
			indirectLight.diffuse =
				DecodeLightmap(UNITY_SAMPLE_TEX2D(unity_Lightmap, i.lightmapUV));
			
			<ins>#if defined(DIRLIGHTMAP_COMBINED)</ins>
				<ins>float4 lightmapDirection = UNITY_SAMPLE_TEX2D(</ins>
					<ins>unity_LightmapInd, i.lightmapUV</ins>
				<ins>);</ins>
			<ins>#endif</ins>
		#else
			indirectLight.diffuse += max(0, ShadeSH9(float4(i.normal, 1)));
		#endif
</pre>
						
						<p>However, this will result in a compile error. That's because a texture variable actually consists of two parts. There's the texture resource, and there's the sampler state. The sampler state determines how the texture is sampled, which includes the filter and clamp mode. Usually, both parts are defined per texture, but this is not required on all platforms. It can also be possible to separate them, which allows us to define a single sampler state for multiple textures.</p>
						
						<p>Because the intensity and the directionality maps are always sampled in the same way, Unity uses a single sampler state for them, when possible. That's why we had to use the <code class="shader">UNITY_SAMPLE_TEX2D</code> macro when sampling the intensity map. The directionality map has been defined without a sampler. To sample it, we have to use the <code class="shader">UNITY_SAMPLE_TEX2D_SAMPLER</code> macro to explicitly tell it which sampler to use.</p>
						
						<pre translate="no" class="shader">				float4 lightmapDirection = <ins>UNITY_SAMPLE_TEX2D_SAMPLER</ins>(
					unity_LightmapInd, <ins>unity_Lightmap,</ins> i.lightmapUV
				);</pre>
					</section>
					
					<section>
						<h3>Using the Direction</h3>
						
						<p>To use the direction, we first have to decode it. Then we can perform the dot product with the normal vector to find the diffuse factor and apply it to the color. But the directionality map doesn't actually contain a unit-length direction, it is a bit more involved than that. Fortunately, we can use the <code class="shader">DecodeDirectionalLightmap</code> function from <em translate="no">UnityCG</em> to both decode the directionality data and perform the shading for us.</p>
						
						<pre translate="no" class="shader">				float4 lightmapDirection = UNITY_SAMPLE_TEX2D_SAMPLER(
					unity_LightmapInd, unity_Lightmap, i.lightmapUV
				);
				<ins>indirectLight.diffuse = DecodeDirectionalLightmap(</ins>
					<ins>indirectLight.diffuse, lightmapDirection, i.normal</ins>
				<ins>);</ins></pre>
						
						<figure>
							<img src="directional-lightmaps/using-directional-lightmaps.png" width="350" height="190">
							<figcaption>Using directional lightmaps.</figcaption>
						</figure>
						
						<aside>
							<h3>What does <code class="shader">DecodeDirectionalLightmap</code> do?</h3>
							<div>
								<p>It actually doesn't calculate the correct diffuse lighting factor. Instead, it uses half Lambert instead. This approach effectively wraps light around surfaces, illuminating the shadowed areas more than they should be. This is needed because the baked lighting doesn't come from a single direction.</p>
								
								<pre translate="no" class="shader">inline half3 DecodeDirectionalLightmap (
	half3 color, fixed4 dirTex, half3 normalWorld
) {
    // In directional (non-specular) mode Enlighten bakes dominant light
	// direction in a way, that using it for half Lambert and then dividing
	// by a "rebalancing coefficient" gives a result close to plain diffuse
	// response lightmaps, but normalmapped.

    // Note that dir is not unit length on purpose. Its length is
	// "directionality", like for the directional specular lightmaps.

    half halfLambert = dot(normalWorld, dirTex.xyz - 0.5) + 0.5;

    return color * halfLambert / max(1e-4h, dirTex.w);
}</pre>
								
								<p>The code comments mention specular lightmaps. These were lightmaps that supported specular lighting, but required more textures, were more expensive to use, and didn't produce good results in most situation. They've been removed since Unity 5.6.</p>
							</div>
						</aside>
					</section>
					
					<a href="directional-lightmaps/directional-lightmaps.unitypackage" download rel="nofollow">unitypackage</a>
				</section>
				
				<section>
					<h2>Light Probes</h2>
					
					<p>Lightmaps only work for static objects, not dynamic ones. As a result, dynamic objects do not fit into a scene with baked lighting. This is extremely obvious when there are no realtime lights at all.</p>
					
					<figure>
						<img src="light-probes/unlit-dynamic-objects.png" width="350" height="190">
						<figcaption>Dynamic objects are obvious.</figcaption>
					</figure>
					
					To better mix static and dynamic objects, we have to somehow apply the baked lighting to dynamic objects as well. Unity has light probes for that. A light probe is a point in space that has information about the lighting at that location. Instead of a texture, it uses spherical harmonics to store this information. When available, these probes will be used for dynamic objects, instead of the global environmental data. So all we have to do is create some probes, wait until they're baked, and our shader will automatically use them.
					
					<section>
						<h3>Creating a Light Probe Group</h3>
						
						<p>Add a group of light probes to the scene via <em translate="no">GameObject / Light / Light Probe Group</em>. This will create a new game object with eight probes in a cube formation. They will immediately be used when shading dynamic objects.</p>
						
						<figure>
							<img src="light-probes/light-probe-group.png" width="180" height="150">
							<figcaption>A new light probe group.</figcaption>
						</figure>
						
						<p>Via its inspector, you can edit the light probe group, after enabling the <em translate="no">Edit Light Probes</em> mode. When enabled, you can select individual probes and either move them in the scene view, or adjust them via the inspector. You can manipulate, duplicate, and delete individual probes as if they were game objects.</p>
						
						<figure>
							<img src="light-probes/inspector.png" width="320" height="146">
							<figcaption>Light probe group inspector.</figcaption>
						</figure>
						
						<p>You do not have to explicitly enable the edit mode. Selecing the group in the scene view is enough to start editing the probes. To stop editing them, deselect the group.</p>
					</section>
					
					<section>
						<h3>Placing Light Probes</h3>
						
						<p>The light probe group divides the volume it encloses into tetrahedral regions. Four probes define the corners of a tetrahedron. These probes are interpolated to determine the final spherical harmonics that are used for a dynamic object, depending on its position inside the tetrahedron. This means that dynamic objects are treated as a single point, so it only works well for fairly small objects.</p>
						
						<p>The tetrahedrons are generated automatically while you edit the probes. You don't need to know their configuration, but their visualization can help you see the relative position of probes.</p>
						
						<p>Placing light probes is a matter of tweaking them until you get acceptable results, just like fiddling with lightmap settings. Begin by encasing the area that will contain dynamic objects.</p>
						
						<figure>
							<img src="light-probes/area.png" width="360" height="230">
							<figcaption>Encasing the area.</figcaption>
						</figure>
						
						<p>Then add more probes depending on how the lighting conditions change. It is essential that you do not place them inside static geometry. Also don't put them on the wrong side of single-sided geometry that isn't transparent.</p>
						
						<figure>
							<img src="light-probes/placing-probes.png" width="360" height="230">
							<figcaption>Placing more probes.</figcaption>
						</figure>
						
						<p>Keep adding and moving probes until you have reasonable lighting conditions in all areas and the transitions between them are acceptable.</p>
						
						<figure>
							<img src="light-probes/tweaking-probes.png" width="360" height="230">
							<figcaption>Tweaking Probes.</figcaption>
						</figure>
						
						<p>You can test the probes by moving dynamic objects around. When a dynamic object is selected, the probes that are currently affecting it will be shown as well. The probes will show their lighting, instead of just being yellow spheres. You can also see the interpolated data used for the dynamic object.</p>
						
						<figure>
							<div class="vid" style="width: 320px; height:174px;"><iframe src='https://gfycat.com/ifr/PreciousFaintGalapagosdove'></iframe></div>
							<figcaption>Moving a dynamic object through a probe group.</figcaption>
						</figure>
						
						<p>The next tutorial is <a href="../part-17/index.html">Mixed Lighting</a>.</p>
					</section>
					
					<a href="light-probes/light-probes.unitypackage" download rel="nofollow">unitypackage</a>
					<a href="Rendering-16.pdf" download rel="nofollow">PDF</a>
				</section>
			</article>
		</main>

		<footer>
			<p>Enjoying the <a href="../../../tutorials">tutorials</a>? Are they useful? Want more?</p>
			<p><b><a href="https://www.patreon.com/catlikecoding">Please support me on Patreon!</a></b></p>
			<p><a href="https://www.patreon.com/catlikecoding"><img src="../../become-a-patron.png" alt="Become my patron!" width="217" height="51"></a></p>
			<p><b><a href="../../donating.html">Or make a direct donation</a>!</b></p>
			<p>made by <a href="../../../../about/index.html" rel="author">Jasper Flick</a></p>
		</footer>
		
		<script src="../../../../jquery2.js"></script>
		<script src="../../tutorials.js"></script>
	</body>
</html>